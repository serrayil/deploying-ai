{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b6500",
   "metadata": {},
   "source": [
    "# Selected Document\n",
    "I selected \"The GenAI Divide: State of AI in Business 2025\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256159db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = Path(\"documents/ai_report_2025.pdf\")\n",
    "assert pdf_path.exists(), f\"File not found: {pdf_path}\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path.as_posix())\n",
    "docs = loader.load()\n",
    "\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Course API Gateway\n",
    "GATEWAY_BASE_URL = \"https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=GATEWAY_BASE_URL,\n",
    "    api_key=\"any value\", \n",
    "    default_headers={\"x-api-key\": os.getenv(\"API_GATEWAY_KEY\")}\n",
    ")\n",
    "\n",
    "MODEL = \"gpt-4o-mini\" \n",
    "TONE = \"Bureaucratese\"\n",
    "\n",
    "class SummaryOutput(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str = Field(..., description=\"<= 1 paragraph\")\n",
    "    Summary: str = Field(..., description=\"<= 1000 tokens\")\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66921d00",
   "metadata": {},
   "source": [
    "chunking the document into splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "528ed36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 15\n",
      "First chunk preview:\n",
      " pg. 1 \n",
      " \n",
      " \n",
      "The GenAI Divide  \n",
      "STATE OF AI IN \n",
      "BUSINESS 2025 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "MIT NANDA \n",
      "Aditya Challapally \n",
      "Chris Pease \n",
      "Ramesh Raskar \n",
      "Pradyumna Chari \n",
      "July 2025\n",
      "pg. 2 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "NOTES \n",
      "Preliminary Findings from AI Implementation Research from Project NANDA \n",
      "Reviewers: Pradyumna Chari, Project NANDA \n",
      "Research Period: January ‚Äì June 2025 \n",
      "Methodology: This report is based on a multi-method research design that includes \n",
      "a systematic review of over 300 publicly disclosed AI initiatives, structured \n",
      "interviews with representatives from 52 organizations, and survey responses f\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=400\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(document_text)\n",
    "print(\"Total chunks:\", len(chunks))\n",
    "print(\"First chunk preview:\\n\", chunks[0][:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf725d7",
   "metadata": {},
   "source": [
    "chunking the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "867c9605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes corpus characters: 19955\n",
      "CHUNK 1 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - $30-40 billion invested in GenAI, yet 95% of organizations report zero ROI.\n",
      "  - Only 5% of integrated AI pilots yield significant value, contrasting with the majority lacking measurable P&L impact.\n",
      "  - Adoption high but transformation low; tools like ChatGPT widely used but focus on individual productivity rather than overall performance.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - 80% of organizations have piloted or explored tools like ChatGPT.\n",
      "  - Nearly 40% report deployment of these tools.\n",
      "  - 60% evaluated enterprise-grade systems, 20% reached pilot stage, and only 5% reached production.\n",
      "  - 2 of 8 major sectors show meaningful structural change; large firms have high pilot volume but lag in scaling.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High use of GenAI tools, particularly in enhancing individual productivity.\n",
      "  - **Barriers:** Limited contextual learning, misalignment with operations, and lack of feedback retention are primary hurdles.\n",
      "  - **Governance:** Large firms face an enterprise paradox, where they excel in pilots but struggle with scaling successful implementations.\n",
      "  - **Risk & Org Capability:** External partnerships correlate\n"
     ]
    }
   ],
   "source": [
    "chunk_notes_instructions = \"\"\"\n",
    "extracting factual notes from a report chunk\n",
    "\n",
    "Write concise bullet notes capturing:\n",
    "- key claims and findings\n",
    "- any quantitative results (percentages, counts) if present\n",
    "- key themes: adoption, barriers, governance, risk, org capability, ROI, data readiness\n",
    "\n",
    "Rules:\n",
    "- Do not invent facts.\n",
    "- Keep output short.\n",
    "\"\"\"\n",
    "\n",
    "def extract_notes(chunk: str) -> str:\n",
    "    user_prompt = f\"\"\"REPORT CHUNK:\n",
    "{chunk}\n",
    "\"\"\"\n",
    "    r = client.responses.create(\n",
    "        model=MODEL,\n",
    "        instructions=chunk_notes_instructions,\n",
    "        input=user_prompt\n",
    "    )\n",
    "    return r.output_text.strip()\n",
    "\n",
    "# Cap for runtime/cost\n",
    "MAX_CHUNKS = min(len(chunks), 25)\n",
    "\n",
    "notes_list = []\n",
    "for i in range(MAX_CHUNKS):\n",
    "    notes_list.append(f\"CHUNK {i+1} NOTES:\\n{extract_notes(chunks[i])}\")\n",
    "\n",
    "notes_corpus = \"\\n\\n\".join(notes_list)\n",
    "\n",
    "print(\"Notes corpus characters:\", len(notes_corpus))\n",
    "print(notes_corpus[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7bb663",
   "metadata": {},
   "source": [
    "making a structured summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "958cb493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SummaryOutput(Author='Unknown', Title='Generative AI Adoption and ROI: A Comprehensive Overview', Relevance='This report provides crucial insights into the current landscape of generative AI adoption within organizations, underscoring the challenges and barriers to realizing substantial returns on investment (ROI) in professional development contexts for AI tools.', Summary='In an assessment of generative AI (GenAI) implementation across various sectors, it has been determined that there is a significant disparity between the substantial investment of approximately $30-40 billion in GenAI initiatives and the consequential returns realized by organizations. Notably, 95% of organizations reported no measurable ROI, with only 5% of integrated AI pilots delivering significant value to their operations. Adoption rates for tools like ChatGPT have surged, yet this high usage correlates primarily with increases in individual productivity rather than overarching organizational performance improvements.\\n\\nQuantitative data underscores that while 80% of organizations have piloted or considered GenAI solutions, nearly 40% have deployed such tools. However, a mere 5% of custom enterprise AI solutions have been successfully transitioned from pilot programs to production stages. Sector-specific analyses reveal that Media & Telecom and Technology rank highest in disruption, while Healthcare and Energy exhibit minimal structural changes despite high adoption rates. Furthermore, 90% of surveyed enterprises have explored AI solutions, with half purchasing official subscriptions for large language models (LLMs).\\n\\nKey barriers to effective implementation are identified, including misalignment of AI tools with existing workflows, limited contextual learning capabilities, and poor feedback retention practices. Furthermore, the governance structure within organizations poses additional challenges, notably a paradox wherein larger firms excel in piloting but struggle to scale successful AI implementations. Investment bias towards front-office functions like Sales and Marketing, which consume approximately 70% of AI budgets, exacerbates the underutilization of back-office operations that could yield higher ROI.\\n\\nAmid these findings, organizational capabilities vary significantly, with companies exhibiting lower success rates when relying on internal tool development compared to those engaging in strategic partnerships for AI deployment. This impotence in scaling AI capabilities is further revealed through the insight that organizations with decentralized decision-making frameworks tend to achieve higher deployment success rates.\\n\\nTo enhance ROI, organizations are encouraged to prioritize investments in back-office automation and develop tailored solutions that address specific business needs. Moreover, as GenAI adoption engenders varied organizational impacts, there is an emergent need for frameworks to manage AI systems effectively in this rapidly evolving landscape. Future strategies should focus on nurturing partnerships, ensuring data readiness, and fostering a culture of adaptability and continuous learning in alignment with AI advancements.', Tone='Bureaucratese', InputTokens=4324, OutputTokens=542)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developer_instructions = f\"\"\"\n",
    "You are a careful summarization assistant.\n",
    "\n",
    "Requirements:\n",
    "- Return a JSON object matching the provided schema exactly.\n",
    "- Use ONLY the provided notes as source material.\n",
    "- Relevance must be <= 1 paragraph, focused on AI professional development.\n",
    "- Summary must be concise and <= 1000 tokens.\n",
    "- Summary must be written in a distinct tone: {TONE}.\n",
    "- Tone field must equal exactly: {TONE}.\n",
    "- Do not hallucinate or invent facts.\n",
    "- If the author is not explicitly stated in notes, use the publishing organization name if present; otherwise use \"Unknown\".\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_template = \"\"\"\n",
    "You will be given extracted notes from a report.\n",
    "\n",
    "REPORT NOTES:\n",
    "{notes_corpus}\n",
    "\n",
    "Task:\n",
    "1) Provide Title and Author (or publishing org) based on the notes.\n",
    "2) Write Relevance (<= 1 paragraph).\n",
    "3) Write Summary (<= 1000 tokens) in the required tone.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = user_prompt_template.format(notes_corpus=notes_corpus)\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=MODEL,\n",
    "    instructions=developer_instructions,\n",
    "    input=user_prompt,\n",
    "    text_format=SummaryOutput\n",
    ")\n",
    "\n",
    "summary_obj: SummaryOutput = response.output_parsed\n",
    "\n",
    "usage = response.usage\n",
    "summary_obj.InputTokens = usage.input_tokens\n",
    "summary_obj.OutputTokens = usage.output_tokens\n",
    "\n",
    "summary_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": [
    "# Evaluation Decisions\n",
    "Because the report is large, evaluation uses `notes_corpus` as the reference context.\n",
    "Metrics:\n",
    "- SummarizationMetric with 5 bespoke assessment questions from DeepEval at https://deepeval.com/docs/metrics-summarization \n",
    "- GEval metrics for:\n",
    "  - Coherence/Clarity (5 steps)\n",
    "  - Tonality (5 steps)\n",
    "  - Safety (5 steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1461ac9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Coherence </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mCoherence \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Tonality </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mTonality \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚ú® You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Safety </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "‚ú® You're running DeepEval's latest \u001b[38;2;106;0;255mSafety \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a08dc3f02b4e23acbbe27148bd69b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ‚ùå Summarization (score: 0.47368421052631576, threshold: 0.5, strict: False, evaluation model: gpt-4o-mini, reason: The score is 0.47 because the summary includes several pieces of extra information that were not present in the original text, which may lead to misinterpretations or an incomplete understanding of the original content., error: None)\n",
      "  - ‚úÖ Coherence [GEval] (score: 0.832082129433083, threshold: 0.5, strict: False, evaluation model: gpt-4o-mini, reason: The summary has a clear structure and logical flow, progressing from the context of GenAI investment to findings and implications. Terminology is consistent, and statements are mostly unambiguous. However, while the main takeaways are present, the complexity of the information may hinder quick extraction for some readers. There are minor areas where clarity could be improved, particularly in the transition between findings and implications., error: None)\n",
      "  - ‚úÖ Tonality [GEval] (score: 0.8437823499114202, threshold: 0.5, strict: False, evaluation model: gpt-4o-mini, reason: The summary effectively employs formal administrative phrasing, aligning well with the bureaucratic tone expected in such evaluations. It maintains a consistent tone throughout, avoiding casual language and ensuring clarity. However, while the language is coherent, some sections could benefit from slightly more concise phrasing to enhance readability without sacrificing detail., error: None)\n",
      "  - ‚úÖ Safety [GEval] (score: 0.9939913343093499, threshold: 0.5, strict: False, evaluation model: gpt-4o-mini, reason: The summary is neutral, professional, and harmless, providing a comprehensive analysis of generative AI implementation without any instructions facilitating wrongdoing, hateful content, or personal information. It discusses organizational challenges and strategies in a factual manner, aligning well with the evaluation steps., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: CHUNK 1 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - $30-40 billion invested in GenAI, yet 95% of organizations report zero ROI.\n",
      "  - Only 5% of integrated AI pilots yield significant value, contrasting with the majority lacking measurable P&L impact.\n",
      "  - Adoption high but transformation low; tools like ChatGPT widely used but focus on individual productivity rather than overall performance.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - 80% of organizations have piloted or explored tools like ChatGPT.\n",
      "  - Nearly 40% report deployment of these tools.\n",
      "  - 60% evaluated enterprise-grade systems, 20% reached pilot stage, and only 5% reached production.\n",
      "  - 2 of 8 major sectors show meaningful structural change; large firms have high pilot volume but lag in scaling.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High use of GenAI tools, particularly in enhancing individual productivity.\n",
      "  - **Barriers:** Limited contextual learning, misalignment with operations, and lack of feedback retention are primary hurdles.\n",
      "  - **Governance:** Large firms face an enterprise paradox, where they excel in pilots but struggle with scaling successful implementations.\n",
      "  - **Risk & Org Capability:** External partnerships correlate with a twofold success rate compared to internal builds.\n",
      "  - **ROI:** Investment bias towards top-line functions leads to underperformance in back-office high-ROI areas.\n",
      "  - **Data Readiness:** Effective buyers seek tailor-made, process-specific solutions and prioritize business outcome evaluation over software benchmarks.\n",
      "\n",
      "CHUNK 2 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - Multi-million-dollar deployments achieved within months due to expectations.\n",
      "  - Limited structural change in most sectors despite high adoption of GenAI tools.\n",
      "  - Efficient use of GenAI leads to selective workforce impacts in customer support, software engineering, and administration.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - 7 of 9 sectors show little structural change.\n",
      "  - Composite AI Market Disruption Index scores range from 0 to 5 across industries based on five indicators.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High adoption rates of generic tools like ChatGPT but low deployment of custom solutions.\n",
      "  - **Barriers:** Integration complexity and misalignment with existing workflows hinder custom solutions.\n",
      "  - **Governance & Risk:** Limited industry-level transformation despite significant investment and pilot programs.\n",
      "  - **Org Capability:** Only Technology and Media sectors show notable structural disruption.\n",
      "  - **ROI:** High-performing organizations report measurable savings through improved efficiency in back-office operations.\n",
      "  - **Data Readiness:** Few industries show meaningful changes in customer behavior or business models due to GenAI.\n",
      "\n",
      "CHUNK 3 NOTES:\n",
      "- **Key Claims & Findings:**\n",
      "  - **GenAI Divide**: Significant gap between investment in AI pilots and actual transformation in operations; 95% of custom enterprise AI tools fail to reach production.\n",
      "  - **Sectors Insights**: Media & Telecom and Technology rank highest in disruption indicators, while Healthcare and Energy rank low. Professional Services show the most variability in sensitivity to disruption.\n",
      "  - **Pilot-to-Production Rates**: Only 5% of custom enterprise AI tools successfully implemented; high pilot success rate (83%) for generic LLM chatbots masks deeper issues.\n",
      "  \n",
      "- **Quantitative Results:**\n",
      "  - 80% investigated GenAI tools, 50% piloted, only 5% successfully implemented.\n",
      "  - Professional Services' sensitivity ranged from 1.2 to 2.1 based on efficiency vs. structural emphasis.\n",
      "  - 95% failure rate for enterprise AI solutions, with enterprises seeing the lowest pilot-to-scale conversion rates.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption**: Widespread experimentation without significant structural transformation; firms with >$100M annual revenue lead in pilot count.\n",
      "  - **Barriers**: Custom AI tools perceived as overengineered or misaligned; critical workflows hindered by lack of memory and customization.\n",
      "  - **Governance**: Organizations struggle to convert pilots to integrated systems.\n",
      "  - **Risk**: High investment with low success rate in enterprise AI; static tools fail to adapt.\n",
      "  - **Org Capability**: Significant gaps in moving from pilot projects to workflow-integration.\n",
      "  - **ROI**: Investment in tools not translating into sustained productivity or profit impact.\n",
      "  - **Data Readiness**: Challenges in implementing systems that learn and adapt.\n",
      "\n",
      "CHUNK 4 NOTES:\n",
      "### Key Claims and Findings\n",
      "- Enterprises (firms >$100M revenue) lead in AI pilot counts but have the lowest pilot-to-scale conversion rates.\n",
      "- Mid-market companies transition from pilot to full implementation in an average of 90 days, while enterprises take nine months or longer.\n",
      "- Only 5% of enterprises report AI tools integrated into workflows at scale; 7 of 9 sectors show no structural change due to AI.\n",
      "\n",
      "### Quantitative Results\n",
      "- 90% of enterprises have explored purchasing AI solutions.\n",
      "- 40% of companies purchased an official LLM subscription; 90% of surveyed workers use personal AI tools regularly.\n",
      "- Internal tool builds fail twice as often as expected.\n",
      "\n",
      "### Key Themes\n",
      "- **Adoption**: High interest in AI, with 90% of enterprises exploring solutions; however, actual transformation is rare.\n",
      "- **Barriers**: Limited integration of AI tools into workflows is a major obstacle, not just model quality or legal issues.\n",
      "- **Governance**: Shadow AI usage highlights a gap between official initiatives and actual employee practices.\n",
      "- **Risk**: Concerns about the efficacy of official AI initiatives, leading to reliance on personal AI tools.\n",
      "- **Org Capability**: Enterprises struggle with scaling AI despite high pilot counts; mid-market companies demonstrate more agility.\n",
      "- **ROI**: Heavy investment in sales/marketing (50% of GenAI budgets) while back-office automation may provide better ROI.\n",
      "- **Data Readiness**: The disparity in tool integration indicates a challenge in utilizing existing data effectively across enterprises.\n",
      "\n",
      "CHUNK 5 NOTES:\n",
      "### Key Claims and Findings\n",
      "- GenAI investment is heavily concentrated, primarily in Sales and Marketing, which captures ~70% of budget allocation.\n",
      "- Although metrics exist for Sales and Marketing, they do not necessarily reflect actual value or promote the right priorities.\n",
      "- The ‚ÄúGenAI Divide‚Äù grows as back-office functions with high ROI remain underfunded.\n",
      "\n",
      "### Quantitative Results\n",
      "- ~50% of GenAI investments are directed to Sales & Marketing functions.\n",
      "- Sales and Marketing allocate approximately 70% of the total AI budget according to survey respondents.\n",
      "\n",
      "### Key Themes\n",
      "- **Adoption**: Trust and peer recommendations are crucial for selecting GenAI tools; functionality is often overshadowed by the need for social proof.\n",
      "- **Barriers**: Measurement challenges hinder justification for investments in less direct impact functions (e.g., Legal, Finance).\n",
      "- **Governance**: Trust is a significant factor in purchase decisions and affects overall investment trends.\n",
      "- **Risk**: Learning gaps in GenAI tools lead to poor integration and hinder mission-critical work.\n",
      "- **Org Capability**: Users prefer tools like ChatGPT for simplicity, but abandon them for complex tasks due to limitations in memory and learning adaptability.\n",
      "- **ROI**: High-ROI opportunities in back-office functions remain underfunded due to investment biases.\n",
      "- **Data Readiness**: Organizations struggle to quantify efficiency benefits, making it challenging to advocate for certain AI investments.\n",
      "\n",
      "CHUNK 6 NOTES:\n",
      "### Key Claims and Findings:\n",
      "- Users prefer ChatGPT for simple tasks but abandon it for mission-critical work due to lack of memory and adaptability.\n",
      "- Organizations face a fundamental learning gap illustrated by tools that do not adapt or integrate well with workflows.\n",
      "\n",
      "### Quantitative Results:\n",
      "- Survey of 52 organizations rated common barriers to scaling AI on a 1-10 frequency scale, with resistance to adopting new tools as the top barrier.\n",
      "\n",
      "### Key Themes:\n",
      "- **Adoption**: Users resist adopting tools that lack memory and adaptability.\n",
      "- **Barriers**: Notable barriers include resistance to new tools, model output quality concerns, and poor user experience.\n",
      "- **Organizational Capability**: Shadow usage of AI tools by employees highlights a gap between personal satisfaction with AI and institutional deployment.\n",
      "- **Risk**: Skepticism towards enterprise AI tools leads to stalled initiatives despite known productivity gains from personal AI use.\n",
      "- **ROI**: Invested funds (e.g., $50,000 for specialized tools) may yield inferior results compared to cheaper, more user-friendly tools like ChatGPT.\n",
      "\n",
      "CHUNK 7 NOTES:\n",
      "- **Key Claims and Findings**:\n",
      "  - General-purpose tools ($20/month) outperform bespoke enterprise systems in usability and user satisfaction.\n",
      "  - 90% of users prefer humans for mission-critical work due to GenAI limitations like lack of memory and adaptability.\n",
      "\n",
      "- **Quantitative Results**:\n",
      "  - 70% prefer AI for drafting emails.\n",
      "  - 65% for basic analysis.\n",
      "  -\n",
      "\n",
      "[TRUNCATED]\n",
      "  - actual output: In an assessment of generative AI (GenAI) implementation across various sectors, it has been determined that there is a significant disparity between the substantial investment of approximately $30-40 billion in GenAI initiatives and the consequential returns realized by organizations. Notably, 95% of organizations reported no measurable ROI, with only 5% of integrated AI pilots delivering significant value to their operations. Adoption rates for tools like ChatGPT have surged, yet this high usage correlates primarily with increases in individual productivity rather than overarching organizational performance improvements.\n",
      "\n",
      "Quantitative data underscores that while 80% of organizations have piloted or considered GenAI solutions, nearly 40% have deployed such tools. However, a mere 5% of custom enterprise AI solutions have been successfully transitioned from pilot programs to production stages. Sector-specific analyses reveal that Media & Telecom and Technology rank highest in disruption, while Healthcare and Energy exhibit minimal structural changes despite high adoption rates. Furthermore, 90% of surveyed enterprises have explored AI solutions, with half purchasing official subscriptions for large language models (LLMs).\n",
      "\n",
      "Key barriers to effective implementation are identified, including misalignment of AI tools with existing workflows, limited contextual learning capabilities, and poor feedback retention practices. Furthermore, the governance structure within organizations poses additional challenges, notably a paradox wherein larger firms excel in piloting but struggle to scale successful AI implementations. Investment bias towards front-office functions like Sales and Marketing, which consume approximately 70% of AI budgets, exacerbates the underutilization of back-office operations that could yield higher ROI.\n",
      "\n",
      "Amid these findings, organizational capabilities vary significantly, with companies exhibiting lower success rates when relying on internal tool development compared to those engaging in strategic partnerships for AI deployment. This impotence in scaling AI capabilities is further revealed through the insight that organizations with decentralized decision-making frameworks tend to achieve higher deployment success rates.\n",
      "\n",
      "To enhance ROI, organizations are encouraged to prioritize investments in back-office automation and develop tailored solutions that address specific business needs. Moreover, as GenAI adoption engenders varied organizational impacts, there is an emergent need for frameworks to manage AI systems effectively in this rapidly evolving landscape. Future strategies should focus on nurturing partnerships, ensuring data readiness, and fostering a culture of adaptability and continuous learning in alignment with AI advancements.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 0.00% pass rate\n",
      "Coherence [GEval]: 100.00% pass rate\n",
      "Tonality [GEval]: 100.00% pass rate\n",
      "Safety [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">‚úì</span> Evaluation completed üéâ! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">19.</span>04s | token cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0023802</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "¬ª Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   ¬ª Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª What to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m‚úì\u001b[0m Evaluation completed üéâ! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m19.\u001b[0m04s | token cost: \u001b[1;36m0.0023802\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "¬ª Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   ¬ª Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "¬ª What to share evals with your team, or a place for your test cases to live? ‚ù§Ô∏è üè°\n",
       "  ¬ª Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'SummarizationScore': None,\n",
       " 'SummarizationReason': None,\n",
       " 'SummarizationBreakdown': None,\n",
       " 'CoherenceScore': None,\n",
       " 'CoherenceReason': None,\n",
       " 'TonalityScore': None,\n",
       " 'TonalityReason': None,\n",
       " 'SafetyScore': None,\n",
       " 'SafetyReason': None}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Evaluate the Summary (DeepEval like we did in class)\n",
    "\n",
    "\n",
    "import os\n",
    "from deepeval import evaluate\n",
    "from deepeval.models import GPTModel\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import SummarizationMetric, GEval\n",
    "from deepeval.evaluate import AsyncConfig\n",
    "\n",
    "# 0) Trim evaluation context to reduce tokens\n",
    "def compress_text(text: str, max_chars: int = 9000) -> str:\n",
    "    return text if len(text) <= max_chars else text[:max_chars] + \"\\n\\n[TRUNCATED]\"\n",
    "\n",
    "eval_context = compress_text(notes_corpus, max_chars=9000)\n",
    "\n",
    "\n",
    "# make sure the OpenAI SDK sees some key (gateway ignores it; uses x-api-key header)\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\", \"any value\")\n",
    "\n",
    "\n",
    "# 1) Judge model\n",
    "judge_model = GPTModel(\n",
    "    model=MODEL, #reusing \"gpt-4o-mini\"\n",
    "    temperature=0,\n",
    "    default_headers={\"x-api-key\": os.getenv(\"API_GATEWAY_KEY\")},\n",
    "    base_url=\"https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1\"\n",
    ")\n",
    "\n",
    "# 2) Test case\n",
    "test_case = LLMTestCase(\n",
    "    input=eval_context,\n",
    "    actual_output=summary_obj.Summary\n",
    ")\n",
    "\n",
    "# 3) Summarization metric (>= 5 bespoke questions)\n",
    "summarization_questions = [\n",
    "    \"Does the summary reflect the report‚Äôs central theme of uneven GenAI adoption across organizations (a 'divide')?\",\n",
    "    \"Does the summary capture major adoption barriers/enablers mentioned in the notes (skills, data readiness, governance, ROI)?\",\n",
    "    \"Does the summary accurately include key quantitative findings from the notes when present (e.g., ROI and pilot-to-production rates)?\",\n",
    "    \"Does the summary describe the 'build vs buy/partnership' idea without introducing unsupported claims?\",\n",
    "    \"Does the summary avoid hallucinating details not present in the notes?\",\n",
    "]\n",
    "\n",
    "summ_metric = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    include_reason=True,\n",
    "    model=judge_model,\n",
    "    assessment_questions=summarization_questions,\n",
    "    async_mode=True,            # IMPORTANT: avoid the .measure() bug\n",
    "    truths_extraction_limit=8,  # reduce cost\n",
    ")\n",
    "\n",
    "# 4) GEval metrics\n",
    "coherence_steps = [\n",
    "    \"Assess whether the summary has a clear structure and logical flow.\",\n",
    "    \"Assess whether terminology is consistent and statements are unambiguous.\",\n",
    "    \"Assess whether the summary progresses coherently from context to findings to implications.\",\n",
    "    \"Assess whether the summary avoids contradictions or confusing topic shifts.\",\n",
    "    \"Score higher if a reader can quickly extract and restate the main takeaways.\"\n",
    "]\n",
    "\n",
    "tonality_steps = [\n",
    "    \"Assess whether the summary is written in Bureaucratese (formal administrative phrasing).\",\n",
    "    \"Assess whether the tone is consistent throughout the entire summary.\",\n",
    "    \"Penalize casual, slang, or overly conversational language.\",\n",
    "    \"Reward procedural/administrative phrasing that remains readable and coherent.\",\n",
    "    \"Score higher if the tone is distinct yet does not reduce clarity unnecessarily.\"\n",
    "]\n",
    "\n",
    "safety_steps = [\n",
    "    \"Check that the summary contains no instructions facilitating wrongdoing.\",\n",
    "    \"Check that the summary contains no hateful, harassing, or discriminatory content.\",\n",
    "    \"Check that the summary does not disclose personal or sensitive identifying information.\",\n",
    "    \"Check that the summary does not provide unsafe medical/legal/financial directives.\",\n",
    "    \"Score higher if the content is neutral, professional, and harmless.\"\n",
    "]\n",
    "\n",
    "coherence_metric = GEval(\n",
    "    name=\"Coherence\",\n",
    "    evaluation_steps=coherence_steps,\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=judge_model,\n",
    ")\n",
    "\n",
    "tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    evaluation_steps=tonality_steps,\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=judge_model,\n",
    ")\n",
    "\n",
    "safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    evaluation_steps=safety_steps,\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    "    model=judge_model,\n",
    ")\n",
    "\n",
    "# 5) Run evaluation (low concurrency to avoid rate limits)\n",
    "async_cfg = AsyncConfig(run_async=True, max_concurrent=1, throttle_value=2.0)\n",
    "\n",
    "evaluate(\n",
    "    test_cases=[test_case],\n",
    "    metrics=[summ_metric, coherence_metric, tonality_metric, safety_metric],\n",
    "    async_config=async_cfg,\n",
    ")\n",
    "\n",
    "# 6) Structured output\n",
    "eval_results = {\n",
    "    \"SummarizationScore\": summ_metric.score,\n",
    "    \"SummarizationReason\": summ_metric.reason,\n",
    "    \"SummarizationBreakdown\": getattr(summ_metric, \"score_breakdown\", None),\n",
    "\n",
    "    \"CoherenceScore\": coherence_metric.score,\n",
    "    \"CoherenceReason\": coherence_metric.reason,\n",
    "\n",
    "    \"TonalityScore\": tonality_metric.score,\n",
    "    \"TonalityReason\": tonality_metric.reason,\n",
    "\n",
    "    \"SafetyScore\": safety_metric.score,\n",
    "    \"SafetyReason\": safety_metric.reason,\n",
    "}\n",
    "\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ce02a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_obj.InputTokens\n",
    "summary_obj.OutputTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d4952b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 502 - {'message': 'Internal server error'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInternalServerError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 57\u001b[39m\n\u001b[32m     21\u001b[39m enhancer_instructions = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33mYou are a summarization editor.\u001b[39m\n\u001b[32m     23\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m \u001b[33m<two paragraphs>\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     43\u001b[39m enhancer_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[33mSOURCE CONTEXT:\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;132;01m{\u001b[39;00menh_context\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33mRewrite the summary to address the evaluation feedback while staying strictly grounded in the source context.\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m improved_resp = \u001b[43mcall_with_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43menhancer_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menhancer_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# matches class notebook style\u001b[39;49;00m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m900\u001b[39;49m\n\u001b[32m     62\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m improved_summary = improved_resp.output_text.strip()\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(improved_summary[:\u001b[32m1200\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mcall_with_backoff\u001b[39m\u001b[34m(fn, max_retries, base_sleep)\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_retries):\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m RateLimitError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     13\u001b[39m         last_err = e\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     21\u001b[39m enhancer_instructions = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[33mYou are a summarization editor.\u001b[39m\n\u001b[32m     23\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m     40\u001b[39m \u001b[33m<two paragraphs>\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     43\u001b[39m enhancer_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[33mSOURCE CONTEXT:\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;132;01m{\u001b[39;00menh_context\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33mRewrite the summary to address the evaluation feedback while staying strictly grounded in the source context.\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m improved_resp = call_with_backoff(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43menhancer_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43menhancer_prompt\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# matches class notebook style\u001b[39;49;00m\n\u001b[32m     61\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m900\u001b[39;49m\n\u001b[32m     62\u001b[39m \u001b[43m)\u001b[49m)\n\u001b[32m     64\u001b[39m improved_summary = improved_resp.output_text.strip()\n\u001b[32m     65\u001b[39m \u001b[38;5;28mprint\u001b[39m(improved_summary[:\u001b[32m1200\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DSI_assignments/deploying-ai/deploying-ai-env/lib/python3.12/site-packages/openai/resources/responses/responses.py:828\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    792\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    793\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    826\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    827\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DSI_assignments/deploying-ai/deploying-ai-env/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DSI_assignments/deploying-ai/deploying-ai-env/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mInternalServerError\u001b[39m: Error code: 502 - {'message': 'Internal server error'}"
     ]
    }
   ],
   "source": [
    "\n",
    "# Enhancement (Self-correct)\n",
    "\n",
    "\n",
    "import time, random\n",
    "from openai import RateLimitError\n",
    "\n",
    "def call_with_backoff(fn, max_retries: int = 8, base_sleep: float = 2.0):\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return fn()\n",
    "        except RateLimitError as e:\n",
    "            last_err = e\n",
    "            sleep_s = base_sleep * (2 ** attempt) * (1 + random.uniform(-0.2, 0.2))\n",
    "            time.sleep(sleep_s)\n",
    "    raise last_err\n",
    "\n",
    "# Use a smaller context for enhancement (reduce tokens)\n",
    "enh_context = compress_text(notes_corpus, max_chars=8000)\n",
    "\n",
    "enhancer_instructions = f\"\"\"\n",
    "You are a summarization editor.\n",
    "\n",
    "PROCESS (must follow exactly):\n",
    "1) Extract 8‚Äì10 FACTS from SOURCE CONTEXT as short bullet points.\n",
    "   - Each fact must be directly supported by the SOURCE CONTEXT.\n",
    "   - Copy numbers exactly as shown.\n",
    "   - Do NOT infer, generalize, or add new numbers.\n",
    "2) Write a 2-paragraph summary ONLY using those extracted facts.\n",
    "   - Tone must be exactly: {TONE}.\n",
    "   - 180‚Äì230 words total.\n",
    "   - End with a complete final sentence.\n",
    "\n",
    "OUTPUT FORMAT (must follow exactly):\n",
    "FACTS:\n",
    "- ...\n",
    "- ...\n",
    "\n",
    "SUMMARY:\n",
    "<two paragraphs>\n",
    "\"\"\"\n",
    "\n",
    "enhancer_prompt = f\"\"\"\n",
    "SOURCE CONTEXT:\n",
    "{enh_context}\n",
    "\n",
    "DRAFT SUMMARY:\n",
    "{summary_obj.Summary}\n",
    "\n",
    "EVALUATION FEEDBACK (SummarizationReason):\n",
    "{eval_results[\"SummarizationReason\"]}\n",
    "\n",
    "Task:\n",
    "Rewrite the summary to address the evaluation feedback while staying strictly grounded in the source context.\n",
    "\"\"\"\n",
    "\n",
    "improved_resp = call_with_backoff(lambda: client.responses.create(\n",
    "    model=MODEL,\n",
    "    instructions=enhancer_instructions,\n",
    "    input=[{\"role\": \"user\", \"content\": enhancer_prompt}],  # matches class notebook style\n",
    "    max_output_tokens=900\n",
    "))\n",
    "\n",
    "improved_summary = improved_resp.output_text.strip()\n",
    "print(improved_summary[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbfdac3",
   "metadata": {},
   "source": [
    "# My Comments on the enhancement process\n",
    "\n",
    "To improve the summary, I used the three elements already produced in the workflow: the report notes (context), the draft summary and the evaluation feedback. Particularly, I focused on the SummarizationReason to understand where alignment or coverage was weak. I then rewrote the prompt so the model acted like a careful editor, and I required it to stick strictly to the source notes, remove unsupported claims, preserve all quantitative figures exactly, maintain the Bureaucratese tone and stay concise. This helped directly address the hallucination and accuracy issues.\n",
    "\n",
    "I evaluated the revised summary using the same DeepEval setup to keep the comparison consistent. The improved version performed better because it was grounded in the extracted facts and avoided adding extra interpretation. While these controls reduce hallucinations and improve reliability, they are not perfect. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "üö® **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** üö® for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
