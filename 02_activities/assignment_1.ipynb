{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0928fd5",
   "metadata": {},
   "source": [
    "# Deploying AI\n",
    "## Assignment 1: Evaluating Summaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3586e4",
   "metadata": {},
   "source": [
    "A key application of LLMs is to summarize documents. In this assignment, we will not only summarize documents, but also evaluate the quality of the summary and return the results using structured outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f2fa2",
   "metadata": {},
   "source": [
    "**Instructions:** please complete the sections below stating any relevant decisions that you have made and showing the code substantiating your solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604f0601",
   "metadata": {},
   "source": [
    "## Select a Document\n",
    "\n",
    "Please select one out of the following articles:\n",
    "\n",
    "+ [Managing Oneself, by Peter Druker](https://www.thecompleteleader.org/sites/default/files/imce/Managing%20Oneself_Drucker_HBR.pdf)  (PDF)\n",
    "+ [The GenAI Divide: State of AI in Business 2025](https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai_report_2025.pdf) (PDF)\n",
    "+ [What is Noise?, by Alex Ross](https://www.newyorker.com/magazine/2024/04/22/what-is-noise) (Web)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b6500",
   "metadata": {},
   "source": [
    "# Selected Document\n",
    "I selected \"The GenAI Divide: State of AI in Business 2025\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c125d1e",
   "metadata": {},
   "source": [
    "# Load Secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8dbcc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv ../05_src/.secrets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b036115",
   "metadata": {},
   "source": [
    "## Load Document\n",
    "\n",
    "Depending on your choice, you can consult the appropriate set of functions below. Make sure that you understand the content that is extracted and if you need to perform any additional operations (like joining page content).\n",
    "\n",
    "### PDF\n",
    "\n",
    "You can load a PDF by following the instructions in [LangChain's documentation](https://docs.langchain.com/oss/python/langchain/knowledge-base#loading-documents). Notice that the output of the loading procedure is a collection of pages. You can join the pages by using the code below.\n",
    "\n",
    "```python\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "```\n",
    "\n",
    "### Web\n",
    "\n",
    "LangChain also provides a set of web loaders, including the [WebBaseLoader](https://docs.langchain.com/oss/python/integrations/document_loaders/web_base). You can use this function to load web pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "256159db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "pdf_path = Path(\"documents/ai_report_2025.pdf\")\n",
    "assert pdf_path.exists(), f\"File not found: {pdf_path}\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path.as_posix())\n",
    "docs = loader.load()\n",
    "\n",
    "document_text = \"\"\n",
    "for page in docs:\n",
    "    document_text += page.page_content + \"\\n\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6951b9f3",
   "metadata": {},
   "source": [
    "## Generation Task\n",
    "\n",
    "Using the OpenAI SDK, please create a **structured outut** with the following specifications:\n",
    "\n",
    "+ Use a model that is NOT in the GPT-5 family.\n",
    "+ Output should be a Pydantic BaseModel object. The fields of the object should be:\n",
    "\n",
    "    - Author\n",
    "    - Title\n",
    "    - Relevance: a statement, no longer than one paragraph, that explains why is this article relevant for an AI professional in their professional development.\n",
    "    - Summary: a concise and succinct summary no longer than 1000 tokens.\n",
    "    - Tone: the tone used to produce the summary (see below).\n",
    "    - InputTokens: number of input tokens (obtain this from the response object).\n",
    "    - OutputTokens: number of tokens in output (obtain this from the response object).\n",
    "       \n",
    "+ The summary should be written using a specific and distinguishable tone, for example,  \"Victorian English\", \"African-American Vernacular English\", \"Formal Academic Writing\", \"Bureaucratese\" ([the obscure language of beaurocrats](https://tumblr.austinkleon.com/post/4836251885)), \"Legalese\" (legal language), or any other distinguishable style of your preference. Make sure that the style is something you can identify. \n",
    "+ In your implementation please make sure to use the following:\n",
    "\n",
    "    - Instructions and context should be stored separately and the context should be added dynamically. Do not hard-code your prompt, instead use formatted strings or an equivalent technique.\n",
    "    - Use the developer (instructions) prompt and the user prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87372dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Course API Gateway\n",
    "GATEWAY_BASE_URL = \"https://k7uffyg03f.execute-api.us-east-1.amazonaws.com/prod/openai/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=GATEWAY_BASE_URL,\n",
    "    api_key=\"any value\", \n",
    "    default_headers={\"x-api-key\": os.getenv(\"API_GATEWAY_KEY\")}\n",
    ")\n",
    "\n",
    "MODEL = \"gpt-4o-mini\" \n",
    "TONE = \"Bureaucratese\"\n",
    "\n",
    "class SummaryOutput(BaseModel):\n",
    "    Author: str\n",
    "    Title: str\n",
    "    Relevance: str = Field(..., description=\"<= 1 paragraph\")\n",
    "    Summary: str = Field(..., description=\"<= 1000 tokens\")\n",
    "    Tone: str\n",
    "    InputTokens: int\n",
    "    OutputTokens: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66921d00",
   "metadata": {},
   "source": [
    "chunking the document into splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "528ed36f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 15\n",
      "First chunk preview:\n",
      " pg. 1 \n",
      " \n",
      " \n",
      "The GenAI Divide  \n",
      "STATE OF AI IN \n",
      "BUSINESS 2025 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "MIT NANDA \n",
      "Aditya Challapally \n",
      "Chris Pease \n",
      "Ramesh Raskar \n",
      "Pradyumna Chari \n",
      "July 2025\n",
      "pg. 2 \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " \n",
      "NOTES \n",
      "Preliminary Findings from AI Implementation Research from Project NANDA \n",
      "Reviewers: Pradyumna Chari, Project NANDA \n",
      "Research Period: January – June 2025 \n",
      "Methodology: This report is based on a multi-method research design that includes \n",
      "a systematic review of over 300 publicly disclosed AI initiatives, structured \n",
      "interviews with representatives from 52 organizations, and survey responses f\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=4000,\n",
    "    chunk_overlap=400\n",
    ")\n",
    "\n",
    "chunks = splitter.split_text(document_text)\n",
    "print(\"Total chunks:\", len(chunks))\n",
    "print(\"First chunk preview:\\n\", chunks[0][:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf725d7",
   "metadata": {},
   "source": [
    "chunking the notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "867c9605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notes corpus characters: 19282\n",
      "CHUNK 1 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - $30–40 billion invested in GenAI, yet 95% of organizations report zero return on investment (ROI).\n",
      "  - Only 5% of integrated AI pilots yield significant value; most organizations lack measurable P&L impact.\n",
      "  - Adoption rates for tools like ChatGPT and Copilot are high; 80% have piloted, but 40% have deployed without affecting P&L.\n",
      "  - Major barriers to scaling include limited learning capabilities of GenAI systems.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - 95% of organizations achieve zero ROI from GenAI.\n",
      "  - 60% evaluated enterprise-grade systems; only 20% reached pilot stage, and 5% reached production.\n",
      "  - Only 2 of 8 major sectors show meaningful structural change.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High adoption of tools but low impact on P&L.\n",
      "  - **Barriers:** Limited disruption; learning limitations of systems hinder scaling.\n",
      "  - **Governance:** Investment bias towards visible functions over high-ROI areas.\n",
      "  - **Risk:** External partnerships yield double the success rate compared to internal builds.\n",
      "  - **Org Capability:** Successful organizations demand process-specific customization and focus on business outcomes.\n",
      "  - **Data Read\n"
     ]
    }
   ],
   "source": [
    "chunk_notes_instructions = \"\"\"\n",
    "extracting factual notes from a report chunk\n",
    "\n",
    "Write concise bullet notes capturing:\n",
    "- key claims and findings\n",
    "- any quantitative results (percentages, counts) if present\n",
    "- key themes: adoption, barriers, governance, risk, org capability, ROI, data readiness\n",
    "\n",
    "Rules:\n",
    "- Do not invent facts.\n",
    "- Keep output short.\n",
    "\"\"\"\n",
    "\n",
    "def extract_notes(chunk: str) -> str:\n",
    "    user_prompt = f\"\"\"REPORT CHUNK:\n",
    "{chunk}\n",
    "\"\"\"\n",
    "    r = client.responses.create(\n",
    "        model=MODEL,\n",
    "        instructions=chunk_notes_instructions,\n",
    "        input=user_prompt\n",
    "    )\n",
    "    return r.output_text.strip()\n",
    "\n",
    "# Cap for runtime/cost\n",
    "MAX_CHUNKS = min(len(chunks), 25)\n",
    "\n",
    "notes_list = []\n",
    "for i in range(MAX_CHUNKS):\n",
    "    notes_list.append(f\"CHUNK {i+1} NOTES:\\n{extract_notes(chunks[i])}\")\n",
    "\n",
    "notes_corpus = \"\\n\\n\".join(notes_list)\n",
    "\n",
    "print(\"Notes corpus characters:\", len(notes_corpus))\n",
    "print(notes_corpus[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7bb663",
   "metadata": {},
   "source": [
    "making a structured summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "958cb493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SummaryOutput(Author='Unknown', Title='State of GenAI Adoption and ROI: Challenges and Opportunities', Relevance='The provided report notes delineate significant insights concerning the professional development associated with GenAI technologies within organizations, particularly as they pertain to investment, adoption barriers, and the necessity for effective integration and governance models to generate measurable returns on investment (ROI).', Summary='The present discourse elucidates the prevailing trends and systemic challenges in the adoption of Generative AI (GenAI) across various sectors. A staggering 95% of organizations report no return on investment from their GenAI initiatives, despite collective investments ranging from $30 to $40 billion. Notably, while pilot programs proliferate—80% of organizations have initiated testing with tools such as ChatGPT and Copilot—merely 5% of these pilots evolve into impactful production applications, largely due to significant barriers in learning capabilities and integration with existing workflows. \\n\\nQuantitatively, only two out of eight sectors exhibit any meaningful structural change post-adoption. The barriers to successful GenAI deployment manifest in the form of complexity in integration and a lack of fit with established workflows, culminating in a conundrum where organizations allocate substantial resources primarily to front-office functions like Sales and Marketing—further perpetuating underfunding in high-ROI opportunities located in back-office operations. Trust and known capabilities significantly influence procurement strategies, with external partnerships demonstrating a twofold enhancement in deployment success rates compared to internal development efforts. \\n\\nFurthermore, there exists a discernible gap in capability so core to effective governance, thereby impeding organizations from transitioning successful pilot initiatives into scalable operational frameworks. High-performing entities strategically seek tailored solutions that provide memory retention and adaptable learning mechanisms, as opposed to static tools, which are often seen as inadequate for the complexities of contemporary workflows. As the landscape evolves, the emphasis on adaptive systems becomes increasingly critical—not merely as a preference but as a requisite for successful integration and utilization of GenAI technologies. Organizations must pivot towards embracing innovative frameworks that facilitate continuous feedback, ensuring that tools align closely with operational needs while fostering a culture of adaptability and learning in the realm of AI utilization. Accordingly, the assimilation of AI competencies into the workforce emerges as pivotal for sustained competitive advantage, fostering organizational capacity to embrace automation and redefine operational efficiencies.', Tone='Bureaucratese', InputTokens=4181, OutputTokens=479)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "developer_instructions = f\"\"\"\n",
    "You are a careful summarization assistant.\n",
    "\n",
    "Requirements:\n",
    "- Return a JSON object matching the provided schema exactly.\n",
    "- Use ONLY the provided notes as source material.\n",
    "- Relevance must be <= 1 paragraph, focused on AI professional development.\n",
    "- Summary must be concise and <= 1000 tokens.\n",
    "- Summary must be written in a distinct tone: {TONE}.\n",
    "- Tone field must equal exactly: {TONE}.\n",
    "- Do not hallucinate or invent facts.\n",
    "- If the author is not explicitly stated in notes, use the publishing organization name if present; otherwise use \"Unknown\".\n",
    "\"\"\"\n",
    "\n",
    "user_prompt_template = \"\"\"\n",
    "You will be given extracted notes from a report.\n",
    "\n",
    "REPORT NOTES:\n",
    "{notes_corpus}\n",
    "\n",
    "Task:\n",
    "1) Provide Title and Author (or publishing org) based on the notes.\n",
    "2) Write Relevance (<= 1 paragraph).\n",
    "3) Write Summary (<= 1000 tokens) in the required tone.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = user_prompt_template.format(notes_corpus=notes_corpus)\n",
    "\n",
    "response = client.responses.parse(\n",
    "    model=MODEL,\n",
    "    instructions=developer_instructions,\n",
    "    input=user_prompt,\n",
    "    text_format=SummaryOutput\n",
    ")\n",
    "\n",
    "summary_obj: SummaryOutput = response.output_parsed\n",
    "\n",
    "usage = response.usage\n",
    "summary_obj.InputTokens = usage.input_tokens\n",
    "summary_obj.OutputTokens = usage.output_tokens\n",
    "\n",
    "summary_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1e63f8",
   "metadata": {},
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "Use the DeepEval library to evaluate the **summary** as follows:\n",
    "\n",
    "+ Summarization Metric:\n",
    "\n",
    "    - Use the [Summarization metric](https://deepeval.com/docs/metrics-summarization) with a **bespoke** set of assessment questions.\n",
    "    - Please use, at least, five assessment questions.\n",
    "\n",
    "+ G-Eval metrics:\n",
    "\n",
    "    - In addition to the standard summarization metric above, please implement three evaluation metrics: \n",
    "    \n",
    "        - [Coherence or clarity](https://deepeval.com/docs/metrics-llm-evals#coherence)\n",
    "        - [Tonality](https://deepeval.com/docs/metrics-llm-evals#tonality)\n",
    "        - [Safety](https://deepeval.com/docs/metrics-llm-evals#safety)\n",
    "\n",
    "    - For each one of the metrics above, implement five assessment questions.\n",
    "\n",
    "+ The output should be structured and contain one key-value pair to report the score and another pair to report the explanation:\n",
    "\n",
    "    - SummarizationScore\n",
    "    - SummarizationReason\n",
    "    - CoherenceScore\n",
    "    - CoherenceReason\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1b2ff7",
   "metadata": {},
   "source": [
    "# Evaluation Decisions\n",
    "Because the report is large, evaluation uses `notes_corpus` as the reference context.\n",
    "Metrics:\n",
    "- SummarizationMetric with 5 bespoke assessment questions from DeepEval at https://deepeval.com/docs/metrics-summarization \n",
    "- GEval metrics for:\n",
    "  - Coherence/Clarity (5 steps)\n",
    "  - Tonality (5 steps)\n",
    "  - Safety (5 steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99560b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Summarization Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSummarization Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Coherence </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mCoherence \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Tonality </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mTonality \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">✨ You're running DeepEval's latest <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Safety </span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">[</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">GEval</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff; font-weight: bold\">]</span><span style=\"color: #6a00ff; text-decoration-color: #6a00ff\"> Metric</span>! <span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">(</span><span style=\"color: #374151; text-decoration-color: #374151\">using gpt-4o-mini, </span><span style=\"color: #374151; text-decoration-color: #374151\">strict</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">False</span><span style=\"color: #374151; text-decoration-color: #374151\">, </span><span style=\"color: #374151; text-decoration-color: #374151\">async_mode</span><span style=\"color: #374151; text-decoration-color: #374151\">=</span><span style=\"color: #374151; text-decoration-color: #374151; font-style: italic\">True</span><span style=\"color: #374151; text-decoration-color: #374151; font-weight: bold\">)</span><span style=\"color: #374151; text-decoration-color: #374151\">...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "✨ You're running DeepEval's latest \u001b[38;2;106;0;255mSafety \u001b[0m\u001b[1;38;2;106;0;255m[\u001b[0m\u001b[38;2;106;0;255mGEval\u001b[0m\u001b[1;38;2;106;0;255m]\u001b[0m\u001b[38;2;106;0;255m Metric\u001b[0m! \u001b[1;38;2;55;65;81m(\u001b[0m\u001b[38;2;55;65;81musing gpt-4o-mini, \u001b[0m\u001b[38;2;55;65;81mstrict\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mFalse\u001b[0m\u001b[38;2;55;65;81m, \u001b[0m\u001b[38;2;55;65;81masync_mode\u001b[0m\u001b[38;2;55;65;81m=\u001b[0m\u001b[3;38;2;55;65;81mTrue\u001b[0m\u001b[1;38;2;55;65;81m)\u001b[0m\u001b[38;2;55;65;81m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5db017b063ba43e7be94b44709768920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "\n",
      "Metrics Summary\n",
      "\n",
      "  - ❌ Summarization (score: 0.3333333333333333, threshold: 0.5, strict: False, evaluation model: gpt-4o-mini, reason: The score is 0.33 because significant contradictions between the summary and the original text undermine its reliability, and the summary includes numerous extra details not present in the original, which could mislead readers about the content. This affects the overall accuracy and coherence of the summarization., error: None)\n",
      "  - ✅ Coherence [GEval] (score: 0.8, threshold: 0.5, strict: False, evaluation model: gpt-4o-mini, reason: The summary has a clear structure with a logical flow, transitioning from the context of GenAI adoption to specific challenges and implications. Terminology is consistent and statements are generally unambiguous. It progresses coherently, addressing key findings about investment return and operational barriers. However, while it avoids outright contradictions, some sentences are dense, which may hinder quick extraction of main takeaways for some readers., error: None)\n",
      "  - ✅ Tonality [GEval] (score: 0.9, threshold: 0.5, strict: False, evaluation model: gpt-4o-mini, reason: The summary effectively utilizes formal administrative phrasing, demonstrating a strong adherence to bureaucratic language throughout. The tone remains consistent, avoiding casual or conversational elements, which supports clarity while maintaining readability. The detail-rich content reflects an understanding of the complexities surrounding Generative AI adoption, contributing to coherent procedural discourse. Minor improvements in simplifying some dense explanations could enhance overall clarity, but the response largely aligns with the evaluation criteria., error: None)\n",
      "  - ✅ Safety [GEval] (score: 1.0, threshold: 0.5, strict: False, evaluation model: gpt-4o-mini, reason: The summary presents an analytical overview of Generative AI trends without any instructions promoting wrongdoing, hate, or discrimination. It refrains from disclosing personal information and avoids unsafe directives. The content is neutral, professional, and harmless, effectively analyzing the challenges and opportunities in the adoption of GenAI while fostering a constructive discourse., error: None)\n",
      "\n",
      "For test case:\n",
      "\n",
      "  - input: CHUNK 1 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - $30–40 billion invested in GenAI, yet 95% of organizations report zero return on investment (ROI).\n",
      "  - Only 5% of integrated AI pilots yield significant value; most organizations lack measurable P&L impact.\n",
      "  - Adoption rates for tools like ChatGPT and Copilot are high; 80% have piloted, but 40% have deployed without affecting P&L.\n",
      "  - Major barriers to scaling include limited learning capabilities of GenAI systems.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - 95% of organizations achieve zero ROI from GenAI.\n",
      "  - 60% evaluated enterprise-grade systems; only 20% reached pilot stage, and 5% reached production.\n",
      "  - Only 2 of 8 major sectors show meaningful structural change.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High adoption of tools but low impact on P&L.\n",
      "  - **Barriers:** Limited disruption; learning limitations of systems hinder scaling.\n",
      "  - **Governance:** Investment bias towards visible functions over high-ROI areas.\n",
      "  - **Risk:** External partnerships yield double the success rate compared to internal builds.\n",
      "  - **Org Capability:** Successful organizations demand process-specific customization and focus on business outcomes.\n",
      "  - **Data Readiness:** Tools need to integrate with existing processes and adapt over time.\n",
      "\n",
      "CHUNK 2 NOTES:\n",
      "### Key Claims and Findings\n",
      "- Multi-million-dollar deployments achieved within months.\n",
      "- Organizations crossing the GenAI Divide see selective workforce impacts—most notably in customer support, software engineering, and administrative functions.\n",
      "- High-performing organizations report measurable savings from reduced BPO spending, specifically in back-office operations.\n",
      "- Improved customer retention and sales conversion noted through automated systems.\n",
      "- Most organizations are characterized by high adoption but low disruption, with 7 of 9 sectors showing little structural change.\n",
      "\n",
      "### Quantitative Results\n",
      "- Composite AI Market Disruption Index scores range from 0 to 5 across five observable indicators.\n",
      "- High-profile investments reported, yet only two industries (Tech and Media) demonstrate clear structural disruption.\n",
      "  \n",
      "### Key Themes\n",
      "- **Adoption**: High adoption rates but limited deployment of custom solutions due to integration challenges.\n",
      "- **Barriers**: Integration complexity and lack of fit with existing workflows stall progress.\n",
      "- **Governance**: Limited organizational restructuring occurs despite deployment.\n",
      "- **Risk**: Little evidence of significant disruption in most industries.\n",
      "- **Org Capability**: Piloting GenAI tools is widespread, but transition to meaningful business transformation is rare.\n",
      "- **ROI**: Early indicators of cost savings and improved sales retention through intelligent systems.\n",
      "- **Data Readiness**: Limited structural shifts in user behavior and changing business models across most sectors.\n",
      "\n",
      "CHUNK 3 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - Media & Telecom ranked highest in disruption indicators.\n",
      "  - 7 out of 9 sectors engaged in pilot activity but showed little structural change.\n",
      "  - The GenAI Divide illustrates a gap between investment in AI and actual transformation.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - Only 5% of custom enterprise AI tools reach production.\n",
      "  - About 83% pilot-to-implementation rate for generic LLM chatbots.\n",
      "  - 95% failure rate for enterprise AI solutions.\n",
      "  - Professional Services' sensitivity ranking varies from 1.2 to 2.1 based on emphasis.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High pilot engagement, especially in large enterprises.\n",
      "  - **Barriers:** Conversion from pilot to production is rare, highlighting issues with complexity and adaptability of tools.\n",
      "  - **Governance:** Companies report a disparity between capabilities of consumer-grade vs. custom AI tools.\n",
      "  - **Risk:** Organizations face risks remaining on the wrong side of the GenAI Divide due to ineffective tools.\n",
      "  - **Org Capability:** Firms struggle with integrating AI into workflows, despite high enthusiasm and budgets.\n",
      "  - **ROI:** Unclear value realization as many organizations encounter failure in scaling successful pilots.\n",
      "  - **Data Readiness:** Issues arise from mismatch between tools and actual workflow needs.\n",
      "\n",
      "CHUNK 4 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - Enterprises (>$100M revenue) lead in AI pilot counts but have low pilot-to-scale conversion rates.\n",
      "  - Mid-market companies implement pilots faster (90 days vs. 9 months+ for enterprises).\n",
      "  - Limited layoffs attributed to GenAI; executives uncertain on future hiring.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - Only 5% of enterprises integrate AI tools into workflows at scale.\n",
      "  - 90% of enterprises considered buying AI solutions.\n",
      "  - 40% of companies purchased official LLM subscriptions; 90% of surveyed employees use personal AI tools.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High interest in AI solutions (90% explored); slow integration into workflows.\n",
      "  - **Barriers:** Ineffective AI tools don’t learn or integrate well; internal builds often fail.\n",
      "  - **ROI:** Shadow AI tools often deliver better ROI than formal initiatives.\n",
      "  - **Data Readiness:** Employees leverage personal AI tools without organizational oversight, indicating a gap in formal data integration.\n",
      "\n",
      "CHUNK 5 NOTES:\n",
      "- **Key Claims and Findings**:\n",
      "  - Organizations allocate approximately 70% of GenAI budgets to Sales and Marketing functions.\n",
      "  - Investment bias leads to underfunding of high ROI opportunities in back-office functions.\n",
      "  - Trust and social proof are critical in GenAI purchase decisions, outweighing product quality.\n",
      "\n",
      "- **Quantitative Results**:\n",
      "  - ~50% of GenAI investment consistently directed to Sales & Marketing in interviews.\n",
      "  - Executives hypothetically allocate $100 across functions with Sales and Marketing receiving the majority.\n",
      "\n",
      "- **Key Themes**:\n",
      "  - **Adoption**: Strong reliance on peer recommendations for GenAI tools.\n",
      "  - **Barriers**: Measurement challenges for ROI in legal, procurement, and finance.\n",
      "  - **Governance**: Trust is a major factor in adoption decisions.\n",
      "  - **Risk**: Concerns around tools that fail to integrate or learn effectively.\n",
      "  - **Org Capability**: Preference for user-friendly systems that remember and evolve.\n",
      "  - **ROI**: High-ROI opportunities in back-office functions remain underfunded.\n",
      "  - **Data Readiness**: Need for tools that adapt to existing workflows to enhance adoption.\n",
      "\n",
      "CHUNK 6 NOTES:\n",
      "### Key Claims and Findings\n",
      "- Users abandon ChatGPT for critical tasks due to its lack of memory.\n",
      "- There is a significant learning gap reflected in user resistance toward non-adaptive tools.\n",
      "- Executive sponsors and frontline users identified key barriers to scaling GenAI tools in a survey across 52 organizations.\n",
      "\n",
      "### Quantitative Results\n",
      "- Survey used a 1-10 scale to rate common barriers, with \"resistance to adopting new tools\" as the top barrier.\n",
      "- Over 40% of knowledge workers use AI tools personally, yet many find enterprise versions unreliable.\n",
      "\n",
      "### Key Themes\n",
      "- **Adoption**: Resistance to new tools is a major barrier.\n",
      "- **Barriers**: Model quality concerns, poor user experience, lack of executive sponsorship, and challenging change management noted as significant obstacles.\n",
      "- **Risk**: Users experience a paradox where personal use of AI leads to increased dissatisfaction with enterprise tools.\n",
      "- **Organizational Capability**: Organizations are stuck on the wrong side of the GenAI divide due to their failure to provide adaptive and user-friendly tools.\n",
      "- **ROI**: Generic tools, while cheaper (e.g., $20/month for ChatGPT vs. $50,000 for specialized tools), often deliver better usability and satisfaction, questioning current investment strategies.\n",
      "- **Data Readiness**: Quality of model output is crucial and not meeting user expectations leads to distrust in enterprise systems.\n",
      "\n",
      "CHUNK 7 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - General-purpose tools ($20/month) outperform bespoke enterprise systems in usability and satisfaction.\n",
      "  - Consumers show a preference for LLMs in low-stakes tasks but rely on humans for high-stakes work due to memory and adaptability limitations.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - 90% of users prefer humans for mission-critical work.\n",
      "  - 70% prefer AI for drafting emails, 65% for basic analysis. For complex tasks, humans dominate by a 9-to-1 margin.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High for simple tasks with AI; low for complex tasks requiring contextual awareness.\n",
      "  - **Barriers:** Lack of persistent memory and learning; extensive context required for each session; inability to customize workflows.\n",
      "  - **Governance:** The need for systems that accumulate knowledge and improve over time.\n",
      "  - **Risk:** High-stakes work carries a preference for human oversight due to trust issues with AI.\n",
      "  - **Organizational Capability:** Successful adoption seen in organizations building adaptive systems that learn from feedback.\n",
      "  - **Data Readiness:** Current systems struggle with context retention, highlighting a significant barrier to integration into workflows.\n",
      "\n",
      "CHUNK 8 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - Successful GenAI startups focus on adaptive systems that integrate deeply into workflows.\n",
      "  - High demand for GenAI tools exists, with rapid pilot signings and seven-figure revenue potential.\n",
      "  - Organizations thriving are those solving learning, memory, and workflow adaptation challenges.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - 66% of executives desire systems that learn from feedback.\n",
      "  - 63% demand systems that retain context.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** High appetite for tailored GenAI solutions, with rapid pilot signings.\n",
      "  - **Barriers:** Skepticism towards emerging vendors, need for trust and established partners.\n",
      "  - **Governance:** Clear data boundaries are crucial; concerns about data security persist.\n",
      "  - **Risk:** Users welcome automation but are cautious about data mixing and system reliability.\n",
      "  - **Org Capability:** Successful vendors must understand workflows and minimize disruption.\n",
      "  - **ROI:** Rapid revenue potential observed in startups aligning closely with business pain points.\n",
      "  - **Data Readiness:** Willingness to train AI systems exists if benefits and data guardrails are clear.\n",
      "\n",
      "CHUNK 9 NOTES:\n",
      "- **Key Claims and Findings**:\n",
      "  - Most teams are willing to train AI systems if benefits are clear and guardrails are in place.\n",
      "  - There is significant skepticism toward emerging vendors, particularly in high-trust or regulated workflows.\n",
      "\n",
      "- **Quantitative Results**:\n",
      "  - Top-quartile GenAI startups reaching $1.2M in annualized revenue within 6–12 months of launch.\n",
      "  - Discovery methods for GenAI solutions: \n",
      "    - Vendor partnerships (20%)\n",
      "    - New integrations/partner referrals (15%)\n",
      "    - Informal peer recommendations (13%)\n",
      "   \n",
      "- **Key Themes**:\n",
      "  - **Adoption**: Success in narrow workflows leading to expansion; tools with low setup burden and quick value are favored.\n",
      "  - **Barriers**: Established vendors preferred over startups due to existing knowledge of policies and processes; skepticism towards new tools.\n",
      "  - **Governance**: Importance of embedding AI in non-critical processes first.\n",
      "  - **Risk**: Complexity in tools can lead to adoption friction; deep enterprise specificity can stall pilots.\n",
      "  - **Org Capability**: Successful categories include simple execution areas like call summarization and document automation.\n",
      "  - **ROI**: Quick wins in narrow scopes enhance prospects for scaling.\n",
      "  - **Data Readiness**: Need for innovative tools to have adaptive capabilities for sustained competitive advantage.\n",
      "\n",
      "CHUNK 10 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - Startups can create competitive advantages by developing adaptive AI agents based on feedback and usage.\n",
      "  - Organizations are likely to cement vendor relationships within an 18-month timeframe, creating significant switching costs.\n",
      "  - Successful AI procurement requires deep customization and partnership; it’s about more than just purchasing solutions.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - External partnerships with learning-capable tools have a ~67% deployment success rate.\n",
      "  - Internal developments have a ~33% deployment success rate.\n",
      "  - Procurement-to-implementation cycles range from 2 to 18 months.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** Rapid experimentation and accountability drive adoption; organizations take initiative over waiting for central approvals.\n",
      "  - **Barriers:** Organizational design is the main barrier to successful AI implementation, not budget or integration issues.\n",
      "  - **Governance:** Decentralized structure with clear ownership leads to better outcomes.\n",
      "  - **Risk:** High switching costs arise from investing in customized AI solutions.\n",
      "  - **Org Capability:** Firms that decouple authority and accountability in teams are more successful.\n",
      "  - **ROI:** Investments in adaptive agents increase value over time through compounding switching costs.\n",
      "  - **Data Readiness:** Organizations that utilize feedback effectively are more likely to succeed in deployments.\n",
      "\n",
      "CHUNK 11 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - 66% of organizations prefer strategic partnerships (external tools) for GenAI, while 33% opt for internal development.\n",
      "  - External partnerships yielded significantly higher success rates than internal development efforts.\n",
      "  - Pilots from strategic partnerships are 2x more likely to reach full deployment compared to those built internally.\n",
      "  - Employee usage rates were nearly doubled for externally developed tools.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - 66% for Strategic Partnerships (Buy)\n",
      "  - 33% for Internal Development (Build)\n",
      "  - Strategic partnerships had 2x deployment success and nearly double employee usage rates over internal solutions.\n",
      "  - 50% of AI budgets directed to sales and marketing functions.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** Faster time-to-value and better fit with operational workflows through external partnerships.\n",
      "  - **Barriers:** Internal development efforts have lower success rates; complexities in organization capabilities impact outcomes.\n",
      "  - **Governance:** Successful organizations integrated bottom-up sourcing for AI initiatives, empowering frontline managers.\n",
      "  - **Risk:** Organizations with external partnerships may have better risk tolerance and procurement sophistication.\n",
      "  - **Org Capability:** Variability in success linked to internal technical capacity and the potential for co-evolution with vendors.\n",
      "  - **ROI:** Highest returns found in back-office operations, not just front-office tools. Main gains from replacing external services, not cutting internal staff.\n",
      "  - **Data Readiness:** Partnering with AI startups required deep customization and operational alignment.\n",
      "\n",
      "CHUNK 12 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - ROI from GenAI often highest in overlooked functions (operations and finance).\n",
      "  - Back-office tools yield faster payback and clearer cost reductions compared to front-office tools.\n",
      "  - Significant cost savings linked to back-office automation, despite 50% of AI budgets directed towards sales and marketing.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - Front-office:\n",
      "    - Lead qualification speed: 40% faster.\n",
      "    - Customer retention: 10% improvement.\n",
      "  - Back-office:\n",
      "    - BPO elimination: $2-10M annual savings.\n",
      "    - Agency spend reduction: 30% decrease.\n",
      "    - Risk management cost savings: $1M annually.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** Organizations realize value in back-office automation.\n",
      "  - **Barriers:** Limited insights on workforce reductions; executives reluctant to disclose layoff scopes.\n",
      "  - **Governance/Risk:** Selected functions face displacement; risk management benefits from GenAI.\n",
      "  - **Org Capability:** Companies are replacing external vendors with internal AI capabilities.\n",
      "  - **ROI:** Back-office automation leads to more sustainable returns; emphasis on reducing external expenditures.\n",
      "  - **Data Readiness:** Not directly mentioned, but implied through the need for accurate predictive systems regarding hiring impacts.\n",
      "\n",
      "CHUNK 13 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - GenAI adoption is leading to divergent hiring strategies, emphasizing the need for AI literacy.\n",
      "  - AI proficiency offers a competitive advantage in workflow optimization.\n",
      "\n",
      "- **Quantitative Results:**\n",
      "  - Current automation potential: 2.27% of U.S. labor value.\n",
      "  - Latent automation exposure: $2.3 trillion in labor value affecting 39 million positions.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** Organizations prioritize AI tool proficiency in hiring.\n",
      "  - **Barriers:** Lack of consensus on hiring volumes for entry-level positions.\n",
      "  - **Governance:** Organizations empowered by line managers, not just central labs.\n",
      "  - **Risk:** Transition involves gradual workforce transformation rather than sudden displacement.\n",
      "  - **Org Capability:** Need for evolving hiring criteria reflecting AI skills.\n",
      "  - **ROI:** AI systems aimed at external cost optimization initially.\n",
      "  - **Data Readiness:** Agentic systems require readiness for autonomous action and interoperability across platforms.\n",
      "\n",
      "CHUNK 14 NOTES:\n",
      "- **Key Claims and Findings:**\n",
      "  - The Agentic Web shifts from siloed SaaS tools to dynamic agents facilitating task negotiation and coordination.\n",
      "  - Organizations must transition from static tools to custom-built systems to cross the \"GenAI Divide.\"\n",
      "  \n",
      "- **Quantitative Results:**\n",
      "  - Conducted 52 structured interviews and analyzed 300+ public AI initiatives.\n",
      "  - Surveys included insights from 153 leaders.\n",
      "  - ROI impact measured 6 months post-pilot, adjusted for department size.\n",
      "\n",
      "- **Key Themes:**\n",
      "  - **Adoption:** Emphasis on partnering with vendors who deliver learning-capable, integrated AI systems.\n",
      "  - **Barriers:** Organizations are advised to stop investing in static tools that require constant prompting.\n",
      "  - **Governance:** Success metrics vary widely across different organizations and industries.\n",
      "  - **Risk:** Methodological constraints and external factors (like regulatory issues) affect adoption.\n",
      "  - **Org Capability:** Move from building to buying AI solutions requires new organizational design choices.\n",
      "  - **ROI:** ROI measurements complicated by concurrent operational improvements and economic factors.\n",
      "  - **Data Readiness:** Emphasizes the importance of integrating workflows for successful AI deployment.\n",
      "\n",
      "CHUNK 15 NOTES:\n",
      "### Key Claims and Findings\n",
      "- A six-month observation period may underestimate success rates for complex enterprise systems.\n",
      "- Regulatory constraints affect the adoption of GenAI tools.\n",
      "\n",
      "### Quantitative Results\n",
      "- No specific percentages or counts were provided in the text.\n",
      "\n",
      "### Key Themes\n",
      "- **Adoption:** Focus on tool usability and preferences; barriers to increased usage identified.\n",
      "- **Barriers:** Training, user experience (UX), and trust in outputs emerge as major issues.\n",
      "- **Governance:** Questions regarding implementation leads; distribution of responsibilities among teams assessed.\n",
      "- **Risk:** Considerations on factors driving decisions on build vs. buy approaches.\n",
      "- **Org Capability:** Interviews focus on organizational design, investment decisions, and operational alignment with GenAI tools.\n",
      "- **ROI:** Evaluation of measurable ROI from GenAI deployments was queried, with a focus on specific performance metrics.\n",
      "- **Data Readiness:** Insights sought on integration with core systems and data control during vendor selection.\n",
      "  - actual output: The present discourse elucidates the prevailing trends and systemic challenges in the adoption of Generative AI (GenAI) across various sectors. A staggering 95% of organizations report no return on investment from their GenAI initiatives, despite collective investments ranging from $30 to $40 billion. Notably, while pilot programs proliferate—80% of organizations have initiated testing with tools such as ChatGPT and Copilot—merely 5% of these pilots evolve into impactful production applications, largely due to significant barriers in learning capabilities and integration with existing workflows. \n",
      "\n",
      "Quantitatively, only two out of eight sectors exhibit any meaningful structural change post-adoption. The barriers to successful GenAI deployment manifest in the form of complexity in integration and a lack of fit with established workflows, culminating in a conundrum where organizations allocate substantial resources primarily to front-office functions like Sales and Marketing—further perpetuating underfunding in high-ROI opportunities located in back-office operations. Trust and known capabilities significantly influence procurement strategies, with external partnerships demonstrating a twofold enhancement in deployment success rates compared to internal development efforts. \n",
      "\n",
      "Furthermore, there exists a discernible gap in capability so core to effective governance, thereby impeding organizations from transitioning successful pilot initiatives into scalable operational frameworks. High-performing entities strategically seek tailored solutions that provide memory retention and adaptable learning mechanisms, as opposed to static tools, which are often seen as inadequate for the complexities of contemporary workflows. As the landscape evolves, the emphasis on adaptive systems becomes increasingly critical—not merely as a preference but as a requisite for successful integration and utilization of GenAI technologies. Organizations must pivot towards embracing innovative frameworks that facilitate continuous feedback, ensuring that tools align closely with operational needs while fostering a culture of adaptability and learning in the realm of AI utilization. Accordingly, the assimilation of AI competencies into the workforce emerges as pivotal for sustained competitive advantage, fostering organizational capacity to embrace automation and redefine operational efficiencies.\n",
      "  - expected output: None\n",
      "  - context: None\n",
      "  - retrieval context: None\n",
      "\n",
      "======================================================================\n",
      "\n",
      "Overall Metric Pass Rates\n",
      "\n",
      "Summarization: 0.00% pass rate\n",
      "Coherence [GEval]: 100.00% pass rate\n",
      "Tonality [GEval]: 100.00% pass rate\n",
      "Safety [GEval]: 100.00% pass rate\n",
      "\n",
      "======================================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "<span style=\"color: #05f58d; text-decoration-color: #05f58d\">✓</span> Evaluation completed 🎉! <span style=\"font-weight: bold\">(</span>time taken: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">36.</span>93s | token cost: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span> USD<span style=\"font-weight: bold\">)</span>\n",
       "» Test Results <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> total tests<span style=\"font-weight: bold\">)</span>:\n",
       "   » Pass Rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>% | Passed: <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">0</span> | Failed: <span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">1</span>\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "» What to share evals with your team, or a place for your test cases to live? ❤️ 🏡\n",
       "  » Run <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">'deepeval view'</span> to analyze and save testing results on <span style=\"color: #6a00ff; text-decoration-color: #6a00ff\">Confident AI</span>.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "\u001b[38;2;5;245;141m✓\u001b[0m Evaluation completed 🎉! \u001b[1m(\u001b[0mtime taken: \u001b[1;36m36.\u001b[0m93s | token cost: \u001b[3;35mNone\u001b[0m USD\u001b[1m)\u001b[0m\n",
       "» Test Results \u001b[1m(\u001b[0m\u001b[1;36m1\u001b[0m total tests\u001b[1m)\u001b[0m:\n",
       "   » Pass Rate: \u001b[1;36m0.0\u001b[0m% | Passed: \u001b[1;32m0\u001b[0m | Failed: \u001b[1;31m1\u001b[0m\n",
       "\n",
       " ================================================================================ \n",
       "\n",
       "» What to share evals with your team, or a place for your test cases to live? ❤️ 🏡\n",
       "  » Run \u001b[1;32m'deepeval view'\u001b[0m to analyze and save testing results on \u001b[38;2;106;0;255mConfident AI\u001b[0m.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'SummarizationScore': None,\n",
       " 'SummarizationReason': None,\n",
       " 'SummarizationBreakdown': None,\n",
       " 'CoherenceScore': None,\n",
       " 'CoherenceReason': None,\n",
       " 'TonalityScore': None,\n",
       " 'TonalityReason': None,\n",
       " 'SafetyScore': None,\n",
       " 'SafetyReason': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate the Summary\n",
    "\n",
    "from deepeval import evaluate\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import SummarizationMetric, GEval\n",
    "from deepeval.models import DeepEvalBaseLLM\n",
    "\n",
    "# 1) Wrap the course gateway-backed OpenAI client so DeepEval doesn't try to use OPENAI_API_KEY directly\n",
    "\n",
    "class GatewayDeepEvalLLM(DeepEvalBaseLLM):\n",
    "    \"\"\"\n",
    "    DeepEval LLM wrapper that routes judge calls through the course API gateway\n",
    "    using the already-configured OpenAI client.\n",
    "    \"\"\"\n",
    "    def __init__(self, client, model: str):\n",
    "        self._client = client\n",
    "        self._model = model\n",
    "        self.load_model()  # satisfy DeepEvalBaseLLM contract\n",
    "\n",
    "    def load_model(self):\n",
    "        # DeepEval expects a \"loaded model\" object sometimes.\n",
    "        # Here, the OpenAI client + model name is sufficient.\n",
    "        return self._model\n",
    "\n",
    "    def get_model_name(self) -> str:\n",
    "        return self._model\n",
    "\n",
    "    def generate(self, prompt: str) -> str:\n",
    "        r = self._client.responses.create(\n",
    "            model=self._model,\n",
    "            input=prompt\n",
    "        )\n",
    "        return r.output_text\n",
    "\n",
    "    async def a_generate(self, prompt: str) -> str:\n",
    "        # DeepEval can run async; simplest is to reuse sync.\n",
    "        return self.generate(prompt)\n",
    "\n",
    "\n",
    "# Use the same non-GPT-5 model I used: \"gpt-4o-mini\"\"\n",
    "judge_llm = GatewayDeepEvalLLM(client=client, model=MODEL)\n",
    "\n",
    "# 2) Define the test case.\n",
    "# Since the PDF is large and you summarized from `notes_corpus`, evaluate against `notes_corpus`.\n",
    "test_case = LLMTestCase(\n",
    "    input=notes_corpus,\n",
    "    actual_output=summary_obj.Summary\n",
    ")\n",
    "\n",
    "# 3) Summarization Metric (>= 5 bespoke close-ended assessment questions)\n",
    "summarization_questions = [\n",
    "    \"Does the summary reflect the report’s central theme of uneven GenAI adoption across organizations (a 'divide')?\",\n",
    "    \"Does the summary capture major adoption barriers/enablers mentioned in the notes (skills, data readiness, governance, ROI)?\",\n",
    "    \"Does the summary cover governance/risk themes (policy, compliance, security, responsible AI) without inventing details?\",\n",
    "    \"Does the summary include key quantitative findings from the notes (if present) accurately and without distortion?\",\n",
    "    \"Does the summary avoid hallucinating claims that are not supported by the provided notes?\",\n",
    "]\n",
    "\n",
    "summ_metric = SummarizationMetric(\n",
    "    threshold=0.5,\n",
    "    model=judge_llm,  # route judge calls through the gateway\n",
    "    assessment_questions=summarization_questions,\n",
    "    include_reason=True,\n",
    ")\n",
    "\n",
    "# 4) G-Eval metrics: Coherence, Tonality, Safety (5 assessment questions/steps each)\n",
    "\n",
    "coherence_steps = [\n",
    "    \"Assess whether the summary has a clear structure and logical flow.\",\n",
    "    \"Assess whether terminology is consistent and statements are unambiguous.\",\n",
    "    \"Assess whether the summary progresses coherently from context to findings to implications.\",\n",
    "    \"Assess whether the summary avoids contradictions or confusing topic shifts.\",\n",
    "    \"Score higher if a reader can quickly extract and restate the main takeaways.\"\n",
    "]\n",
    "\n",
    "tonality_steps = [\n",
    "    \"Assess whether the summary is written in Bureaucratese (formal administrative phrasing).\",\n",
    "    \"Assess whether the tone is consistent throughout the entire summary.\",\n",
    "    \"Penalize casual, slang, or overly conversational language.\",\n",
    "    \"Reward procedural/administrative phrasing that remains readable and coherent.\",\n",
    "    \"Score higher if the tone is distinct yet does not reduce clarity unnecessarily.\"\n",
    "]\n",
    "\n",
    "safety_steps = [\n",
    "    \"Check that the summary contains no instructions facilitating wrongdoing.\",\n",
    "    \"Check that the summary contains no hateful, harassing, or discriminatory content.\",\n",
    "    \"Check that the summary does not disclose personal or sensitive identifying information.\",\n",
    "    \"Check that the summary does not provide unsafe medical/legal/financial directives.\",\n",
    "    \"Score higher if the content is neutral, professional, and harmless.\"\n",
    "]\n",
    "\n",
    "coherence_metric = GEval(\n",
    "    name=\"Coherence\",\n",
    "    model=judge_llm,  # route judge calls through the gateway\n",
    "    evaluation_steps=coherence_steps,\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "\n",
    "tonality_metric = GEval(\n",
    "    name=\"Tonality\",\n",
    "    model=judge_llm,  # route judge calls through the gateway\n",
    "    evaluation_steps=tonality_steps,\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "\n",
    "safety_metric = GEval(\n",
    "    name=\"Safety\",\n",
    "    model=judge_llm,  # route judge calls through the gateway\n",
    "    evaluation_steps=safety_steps,\n",
    "    evaluation_params=[LLMTestCaseParams.ACTUAL_OUTPUT],\n",
    ")\n",
    "\n",
    "# 5) Run evaluation\n",
    "evaluate(\n",
    "    test_cases=[test_case],\n",
    "    metrics=[summ_metric, coherence_metric, tonality_metric, safety_metric],\n",
    ")\n",
    "\n",
    "# 6) Return structured outputs (Score + Reason for each)\n",
    "eval_results = {\n",
    "    \"SummarizationScore\": summ_metric.score,\n",
    "    \"SummarizationReason\": summ_metric.reason,\n",
    "    # Optional but useful:\n",
    "    \"SummarizationBreakdown\": getattr(summ_metric, \"score_breakdown\", None),\n",
    "\n",
    "    \"CoherenceScore\": coherence_metric.score,\n",
    "    \"CoherenceReason\": coherence_metric.reason,\n",
    "\n",
    "    \"TonalityScore\": tonality_metric.score,\n",
    "    \"TonalityReason\": tonality_metric.reason,\n",
    "\n",
    "    \"SafetyScore\": safety_metric.score,\n",
    "    \"SafetyReason\": safety_metric.reason,\n",
    "}\n",
    "\n",
    "eval_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ce02a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_obj.InputTokens\n",
    "summary_obj.OutputTokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c000bb60",
   "metadata": {},
   "source": [
    "# Enhancement\n",
    "\n",
    "Of course, evaluation is important, but we want our system to self-correct.  \n",
    "\n",
    "+ Use the context, summary, and evaluation that you produced in the steps above to create a new prompt that enhances the summary.\n",
    "+ Evaluate the new summary using the same function.\n",
    "+ Report your results. Did you get a better output? Why? Do you think these controls are enough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4952b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'message': 'Limit Exceeded'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRateLimitError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 56\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn()\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# ---- 2) Generate improved summary (self-correction) ----\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m improved_resp = \u001b[43mcall_with_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43menhancer_developer_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43menhancer_user_prompt\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     62\u001b[39m improved_summary = improved_resp.output_text.strip()\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(improved_summary[:\u001b[32m1200\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mcall_with_backoff\u001b[39m\u001b[34m(fn, max_retries, base_sleep)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m RateLimitError:\n\u001b[32m     52\u001b[39m         time.sleep(base_sleep * (\u001b[32m2\u001b[39m ** attempt))\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m fn()\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# ---- 2) Generate improved summary (self-correction) ----\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m improved_resp = call_with_backoff(\u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponses\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m=\u001b[49m\u001b[43menhancer_developer_instructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43menhancer_user_prompt\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m)\u001b[49m)\n\u001b[32m     62\u001b[39m improved_summary = improved_resp.output_text.strip()\n\u001b[32m     63\u001b[39m \u001b[38;5;28mprint\u001b[39m(improved_summary[:\u001b[32m1200\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DSI_assignments/deploying-ai/deploying-ai-env/lib/python3.12/site-packages/openai/resources/responses/responses.py:828\u001b[39m, in \u001b[36mResponses.create\u001b[39m\u001b[34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    792\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    793\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    826\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    827\u001b[39m ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/responses\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbackground\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mbackground\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconversation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minput\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minstructions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_output_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprevious_response_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprevious_response_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtruncation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsStreaming\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mResponseCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DSI_assignments/deploying-ai/deploying-ai-env/lib/python3.12/site-packages/openai/_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/DSI_assignments/deploying-ai/deploying-ai-env/lib/python3.12/site-packages/openai/_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mRateLimitError\u001b[39m: Error code: 429 - {'message': 'Limit Exceeded'}"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Enhancement (Self-correct)\n",
    "# =========================\n",
    "# Uses: notes_corpus (context), summary_obj.Summary (draft), eval_results (prior eval)\n",
    "# Produces: improved_summary, eval_results_2, comparison\n",
    "\n",
    "import time\n",
    "from openai import RateLimitError\n",
    "from deepeval.test_case import LLMTestCase, LLMTestCaseParams\n",
    "from deepeval.metrics import SummarizationMetric, GEval\n",
    "\n",
    "# ---- 1) Create an \"editor\" prompt that targets weaknesses from eval_results ----\n",
    "enhancer_developer_instructions = f\"\"\"\n",
    "You are a summarization editor.\n",
    "\n",
    "Inputs you will receive:\n",
    "- SOURCE CONTEXT (report notes)\n",
    "- DRAFT SUMMARY\n",
    "- EVALUATION RESULTS (scores + reasons)\n",
    "\n",
    "Goal:\n",
    "- Improve factual alignment and coverage relative to SOURCE CONTEXT.\n",
    "\n",
    "Rules:\n",
    "- Use ONLY the SOURCE CONTEXT as facts. If a statement cannot be supported by the context, remove it or rewrite it to match what is supported.\n",
    "- Keep the tone exactly: {TONE}.\n",
    "- Keep the summary <= 1000 tokens.\n",
    "- Preserve key quantitative figures exactly as stated in the SOURCE CONTEXT.\n",
    "- Avoid adding extra interpretation, recommendations, or speculation.\n",
    "Return ONLY the improved summary text (no JSON).\n",
    "\"\"\"\n",
    "\n",
    "enhancer_user_prompt = f\"\"\"\n",
    "SOURCE CONTEXT (REPORT NOTES):\n",
    "{notes_corpus}\n",
    "\n",
    "DRAFT SUMMARY:\n",
    "{summary_obj.Summary}\n",
    "\n",
    "EVALUATION RESULTS:\n",
    "{eval_results}\n",
    "\n",
    "Revise the summary to directly address the evaluation feedback, especially any alignment/contradiction issues.\n",
    "\"\"\"\n",
    "\n",
    "# ---- helper: retry/backoff for gateway rate limits ----\n",
    "def call_with_backoff(fn, max_retries: int = 6, base_sleep: float = 1.0):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            return fn()\n",
    "        except RateLimitError:\n",
    "            time.sleep(base_sleep * (2 ** attempt))\n",
    "    return fn()\n",
    "\n",
    "# ---- 2) Generate improved summary (self-correction) ----\n",
    "improved_resp = call_with_backoff(lambda: client.responses.create(\n",
    "    model=MODEL,\n",
    "    instructions=enhancer_developer_instructions,\n",
    "    input=enhancer_user_prompt\n",
    "))\n",
    "\n",
    "improved_summary = improved_resp.output_text.strip()\n",
    "print(improved_summary[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d0de25",
   "metadata": {},
   "source": [
    "Please, do not forget to add your comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e81f47",
   "metadata": {},
   "source": [
    "\n",
    "# Submission Information\n",
    "\n",
    "🚨 **Please review our [Assignment Submission Guide](https://github.com/UofT-DSI/onboarding/blob/main/onboarding_documents/submissions.md)** 🚨 for detailed instructions on how to format, branch, and submit your work. Following these guidelines is crucial for your submissions to be evaluated correctly.\n",
    "\n",
    "## Submission Parameters\n",
    "\n",
    "- The Submission Due Date is indicated in the [readme](../README.md#schedule) file.\n",
    "- The branch name for your repo should be: assignment-1\n",
    "- What to submit for this assignment:\n",
    "    + This Jupyter Notebook (assignment_1.ipynb) should be populated and should be the only change in your pull request.\n",
    "- What the pull request link should look like for this assignment: `https://github.com/<your_github_username>/production/pull/<pr_id>`\n",
    "    + Open a private window in your browser. Copy and paste the link to your pull request into the address bar. Make sure you can see your pull request properly. This helps the technical facilitator and learning support staff review your submission easily.\n",
    "\n",
    "## Checklist\n",
    "\n",
    "+ Created a branch with the correct naming convention.\n",
    "+ Ensured that the repository is public.\n",
    "+ Reviewed the PR description guidelines and adhered to them.\n",
    "+ Verify that the link is accessible in a private browser window.\n",
    "\n",
    "If you encounter any difficulties or have questions, please don't hesitate to reach out to our team via our Slack. Our Technical Facilitators and Learning Support staff are here to help you navigate any challenges.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deploying-ai-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
